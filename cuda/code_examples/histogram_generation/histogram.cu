/* Histogram generation on the GPU. 
	Host-side code.
	Author: Naga Kandasamy
	Date modified: 3/11/2017
*/

// includes, system
#include <stdlib.h>
#include <stdio.h>
#include <sys/time.h>
#include <string.h>
#include <math.h>
#include <float.h>


#define THREAD_BLOCK_SIZE 256
#define NUM_BLOCKS 60 // Define the size of a tile
#define HISTOGRAM_SIZE 256 // Histogram has 256 bins

// includes, kernels
#include "histogram_kernel.cu"

////////////////////////////////////////////////////////////////////////////////
// declaration, forward
void run_test(int);
void compute_on_device(int *, int *, int, int);
void check_for_error(const char *);
extern "C" void compute_gold(int *, int *, int, int);
void check_histogram(int *, int, int);

int 
main( int argc, char** argv) 
{
	if(argc != 2){
		printf("Usage: histogram <num elements> \n");
		exit(0);	
	}
	int num_elements = atoi(argv[1]);
	run_test(num_elements);
	return 0;
}

////////////////////////////////////////////////////////////////////////////////
//! Generate the histogram on the CPU and the GPU and compare results for correctness
////////////////////////////////////////////////////////////////////////////////
void run_test(int num_elements) 
{
	float diff;
	int i; 
	int *histogram_on_cpu = (int *)malloc(sizeof(int) * HISTOGRAM_SIZE); // Space to store histogram generated by the CPU
	int *histogram_on_gpu = (int *)malloc(sizeof(int) * HISTOGRAM_SIZE); // Space to store histogram generated by the GPU

	// Allocate memory on the CPU for the input data
	int size = sizeof(int) * num_elements;
	int *input_data = (int *)malloc(size);
	
	// Randomly generate input data. Initialize the input data to be integer values between 0 and (HISTOGRAM_SIZE - 1)
	for(i = 0; i < num_elements; i++)
		input_data[i] = floorf((HISTOGRAM_SIZE - 1) * (rand()/(float)RAND_MAX));

	printf("Creating histrgram on the CPU.");
	// Compute the reference solution on the CPU
    struct timeval start, stop;	
	gettimeofday(&start, NULL);

	compute_gold(input_data, histogram_on_cpu, num_elements, HISTOGRAM_SIZE);

    gettimeofday(&stop, NULL);
	printf("Elapsed time on the CPU = %f \n",stop.tv_sec - start.tv_sec + (stop.tv_usec - start.tv_usec)/(float)1000000);

	check_histogram(histogram_on_cpu, num_elements, HISTOGRAM_SIZE);
	
	// Compute the result vector on the GPU 
	compute_on_device(input_data, histogram_on_gpu, num_elements, HISTOGRAM_SIZE);
	check_histogram(histogram_on_gpu, num_elements, HISTOGRAM_SIZE);

	// Compute the differences between the CPU and GPU results
	diff = 0.0;
   for(i = 0; i < HISTOGRAM_SIZE; i++)
		diff = diff + abs(histogram_on_cpu[i] - histogram_on_gpu[i]);

	printf("Difference between the CPU and GPU result: %f. \n", diff);
   
	// cleanup memory
	free(input_data);
	free(histogram_on_cpu);
	free(histogram_on_gpu);

	return;
}

// Transfer the input data to the GPU, set up grid and thread dimensions, excute kernel function, and copy result back to the CPU
void compute_on_device(int *input_data, int *histogram, int num_elements, int histogram_size)
{
	int *input_data_on_device = NULL;
	int *histogram_on_device = NULL;

	// Allocate space on the GPU for the input data
	cudaMalloc((void**)&input_data_on_device, num_elements * sizeof(int));
	cudaMemcpy(input_data_on_device, input_data, num_elements * sizeof(int), cudaMemcpyHostToDevice);

	// Allocate space on the GPU for the histogram and initialize the contents to zero
	cudaMalloc((void**)&histogram_on_device, histogram_size * sizeof(int));
	cudaMemset(histogram_on_device, 0, histogram_size * sizeof(int));

 	// Set up the execution grid on the GPU
	dim3 thread_block(THREAD_BLOCK_SIZE, 1, 1);
	dim3 grid(NUM_BLOCKS,1);
	
	printf("Generating histogram on the GPU. \n");
    struct timeval start, stop;	
	gettimeofday(&start, NULL);

	
	// histogram_kernel_slow<<<grid, thread_block>>>(input_data_on_device, histogram_on_device, num_elements, histogram_size); 
	histogram_kernel_fast<<<grid, thread_block>>>(input_data_on_device, histogram_on_device, num_elements, histogram_size); 

	cudaThreadSynchronize();

    gettimeofday(&stop, NULL);
	printf("Elapsed time on the GPU = %f \n",stop.tv_sec - start.tv_sec + (stop.tv_usec - start.tv_usec)/(float)1000000);

	check_for_error("KERNEL FAILURE");

	// Copy the result back from the GPU and store 
	cudaMemcpy(histogram, histogram_on_device, histogram_size * sizeof(int), cudaMemcpyDeviceToHost);
	
	// Free memory on the GPU
	cudaFree(input_data_on_device);
	cudaFree(histogram_on_device);
}

void check_histogram(int *histogram, int num_elements, int histogram_size)
{
	int sum = 0;
	for(int i = 0; i < histogram_size; i++)
		sum += histogram[i];

	printf("Number of histogram entries = %d. \n", sum);
	if(sum == num_elements)
		printf("Histogram generated successfully. \n");
	else
		printf("Error generating histogram. \n");
	printf("\n");
}


void check_for_error(const char *msg)
{
	cudaError_t err = cudaGetLastError();
	if(cudaSuccess != err){
		printf("CUDA ERROR: %s (%s). \n", msg, cudaGetErrorString(err));
		exit(EXIT_FAILURE);
	}
} 
