\documentclass[12.0pt]{article}
\usepackage{graphics, graphicx, cite, fancybox, setspace}
\usepackage{amsfonts, amssymb, amsmath, latexsym, epic, eepic, url}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[letterpaper, left=1in, right=1in, top=1in, bottom=1in]{geometry}
\usepackage{times}

\begin{document}

\title{ECEC 414: High-Performance Computing \\
CUDA Programming Assignment 2}
\author{Prof. Naga Kandasamy, ECE Department, Drexel University}
\maketitle %
\date{}

\noindent The lab is due on November 23, 2014. You may work on the problems in teams of up to two people.
\vspace{12pt}

\noindent \textbf{Matrix-Vector Multiplication.} You will multiply a dense $n \times n $ matrix $A$ with an $n \times 1$ vector $x$ to yield the $n \times 1$ result vector $y$. The serial algorithm is shown below. \vspace{12pt}

\begin{algorithm}[!h]
\begin{algorithmic}[1]
	\STATE \textbf{procedure} VEC\_MAT\_MULT($A$, $x$, $y$)
    \STATE int $i$, $j$;
	\FOR{$i$ := 0 to $n-1$}
        \STATE $y[i] := 0$;
		\FOR{$j$ := 0 to $n-1$}
				\STATE $y[i] := y[i] + A[i, j] \times x[j]$;
			\ENDFOR
	\ENDFOR
\end{algorithmic}
\end{algorithm}

\noindent Edit the \texttt{vec\_mat\_mult\_on\_device()} function in \texttt{vec\_mat\_mult.cu} and the corresponding kernel function in \texttt{vec\_mat\_mult\_kernel.cu} to complete the functionality of the vector-matrix multiplication on the GPU. The CUDA source files for this question are available on BBLearn as a zip file. Your program should accept no arguments. The application will create a randomly initialized matrix and a vector to multiply. After the GPU-based multiplication kernel is invoked, it will then compute the correct solution using the CPU and compare that solution with the GPU-computed solutions. If the solutions match within a certain tolerance, the application will print out ``Test PASSED'' to the screen before exiting. \vspace{12pt}

\noindent Upload all of the files needed to run your code as a single zip file on BBLearn called \texttt{cuda\_lab\_2.zip}. This question will be graded on the following parameters:
\begin{itemize}
\item Make judicial use of the GPU shared memory to obtain the best speedup that you can over the CPU version, for matrix sizes of $4096 \times 4096$ and $8192 \times 8192$. When timing the GPU kernel, you may ignore the CPU-GPU data transfer overhead.

\item Include a brief report describing how you designed your kernel (use code or pseudocode to clarify the discussion) and the amount of speedup obtained over the serial version for both GPU-based versions.
\end{itemize}
\pagebreak

\end{document}
